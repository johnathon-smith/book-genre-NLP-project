{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabbbedf",
   "metadata": {},
   "source": [
    "# Model the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe93c61",
   "metadata": {},
   "source": [
    "For my MVP, I would like to use several algorithms with cross-validation and grid search. The algorithms I plan on using are:\n",
    "\n",
    "* Random Forest Classifier\n",
    "* K-Nearest Neighbors\n",
    "* Gaussian Naive Bayes\n",
    "* Multinomial Naive Bayes\n",
    "* XGBoost (If I can get it to work. I will attempt this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34653ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95609c02",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc9f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurbs = pd.read_csv('blurbs_for_exploration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c92376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>sub-genre</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>lem_char_count</th>\n",
       "      <th>lem_word_count</th>\n",
       "      <th>lem_unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>word_stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>Designed to appeal to the book lover, the Macm...</td>\n",
       "      <td>designed appeal book lover macmillan collector...</td>\n",
       "      <td>design appeal book lover macmillan collector '...</td>\n",
       "      <td>designed appeal book lover macmillan collector...</td>\n",
       "      <td>1102</td>\n",
       "      <td>147</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>96</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>Part of the Penguin Orange Collection, a limit...</td>\n",
       "      <td>part penguin orange collection limitedrun seri...</td>\n",
       "      <td>part penguin orang collect limitedrun seri twe...</td>\n",
       "      <td>part penguin orange collection limitedrun seri...</td>\n",
       "      <td>954</td>\n",
       "      <td>118</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>55</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>Part of a new six-volume series of the best in...</td>\n",
       "      <td>part new sixvolume series best classic horror ...</td>\n",
       "      <td>part new sixvolum seri best classic horror sel...</td>\n",
       "      <td>part new sixvolume series best classic horror ...</td>\n",
       "      <td>1260</td>\n",
       "      <td>173</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.2144</td>\n",
       "      <td>85</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>A USA TODAY BESTSELLER!An Indie Next Pick!An O...</td>\n",
       "      <td>usa today bestselleran indie next pickan octob...</td>\n",
       "      <td>usa today bestselleran indi next pickan octob ...</td>\n",
       "      <td>usa today bestselleran indie next pickan octob...</td>\n",
       "      <td>800</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.9530</td>\n",
       "      <td>63</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>From the New York Times best-selling author of...</td>\n",
       "      <td>new york times bestselling author southern boo...</td>\n",
       "      <td>new york time bestsel author southern book clu...</td>\n",
       "      <td>new york time bestselling author southern book...</td>\n",
       "      <td>603</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.9726</td>\n",
       "      <td>28</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre      sub-genre                                           original  \\\n",
       "0  Horror  ghost-stories  Designed to appeal to the book lover, the Macm...   \n",
       "1  Horror  ghost-stories  Part of the Penguin Orange Collection, a limit...   \n",
       "2  Horror  ghost-stories  Part of a new six-volume series of the best in...   \n",
       "3  Horror  ghost-stories  A USA TODAY BESTSELLER!An Indie Next Pick!An O...   \n",
       "4  Horror  ghost-stories  From the New York Times best-selling author of...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  designed appeal book lover macmillan collector...   \n",
       "1  part penguin orange collection limitedrun seri...   \n",
       "2  part new sixvolume series best classic horror ...   \n",
       "3  usa today bestselleran indie next pickan octob...   \n",
       "4  new york times bestselling author southern boo...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  design appeal book lover macmillan collector '...   \n",
       "1  part penguin orang collect limitedrun seri twe...   \n",
       "2  part new sixvolum seri best classic horror sel...   \n",
       "3  usa today bestselleran indi next pickan octob ...   \n",
       "4  new york time bestsel author southern book clu...   \n",
       "\n",
       "                                          lemmatized  lem_char_count  \\\n",
       "0  designed appeal book lover macmillan collector...            1102   \n",
       "1  part penguin orange collection limitedrun seri...             954   \n",
       "2  part new sixvolume series best classic horror ...            1260   \n",
       "3  usa today bestselleran indie next pickan octob...             800   \n",
       "4  new york time bestselling author southern book...             603   \n",
       "\n",
       "   lem_word_count  lem_unique_word_count  sentence_count  \\\n",
       "0             147                    120               8   \n",
       "1             118                     87               2   \n",
       "2             173                    138               7   \n",
       "3             104                     92               2   \n",
       "4              77                     74               5   \n",
       "\n",
       "   avg_words_per_sentence  sentiment  stopword_count  word_stopword_ratio  \n",
       "0                      18     0.9582              96                 0.65  \n",
       "1                      59     0.9100              55                 0.47  \n",
       "2                      25    -0.2144              85                 0.49  \n",
       "3                      52    -0.9530              63                 0.61  \n",
       "4                      15    -0.9726              28                 0.36  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3588838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21414 entries, 0 to 21413\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   genre                   21414 non-null  object \n",
      " 1   sub-genre               21414 non-null  object \n",
      " 2   original                21414 non-null  object \n",
      " 3   clean                   21414 non-null  object \n",
      " 4   stemmed                 21414 non-null  object \n",
      " 5   lemmatized              21414 non-null  object \n",
      " 6   lem_char_count          21414 non-null  int64  \n",
      " 7   lem_word_count          21414 non-null  int64  \n",
      " 8   lem_unique_word_count   21414 non-null  int64  \n",
      " 9   sentence_count          21414 non-null  int64  \n",
      " 10  avg_words_per_sentence  21414 non-null  int64  \n",
      " 11  sentiment               21414 non-null  float64\n",
      " 12  stopword_count          21414 non-null  int64  \n",
      " 13  word_stopword_ratio     21414 non-null  float64\n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "blurbs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5170ce",
   "metadata": {},
   "source": [
    "# Split the Data\n",
    "\n",
    "Since I will be using cross-validation, I won't need a validation set. Only train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cf8f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16060, 14), (5354, 14))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(blurbs, stratify = blurbs.genre, test_size = .25, random_state = 123)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c35bd3",
   "metadata": {},
   "source": [
    "# Create X and y Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca62c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop(columns = ['genre']), train.genre\n",
    "X_test, y_test = test.drop(columns = ['genre']), test.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffac6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16060, 13), (16060,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check train shapes\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f545e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5354, 13), (5354,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check test shapes\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587cd99",
   "metadata": {},
   "source": [
    "# Scale the X Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fbd4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Fit and transform the data on train \n",
    "X_train[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']] = scaler.fit_transform(X_train[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']])\n",
    "\n",
    "#Transform the data on test\n",
    "X_test[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']] = scaler.transform(X_test[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d68943",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Make predictions using only the engineered features, not the term frequencies or TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab8f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the engineered features\n",
    "X_train_part1 = X_train.drop(columns = ['sub-genre', 'original', 'clean', 'stemmed', 'lemmatized'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b19eebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lem_char_count</th>\n",
       "      <th>lem_word_count</th>\n",
       "      <th>lem_unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>word_stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17405</th>\n",
       "      <td>0.063722</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>0.107901</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.986747</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.041007</td>\n",
       "      <td>0.068819</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.878720</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>0.053889</td>\n",
       "      <td>0.058248</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>0.050461</td>\n",
       "      <td>0.060112</td>\n",
       "      <td>0.092608</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.054450</td>\n",
       "      <td>0.064772</td>\n",
       "      <td>0.105353</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.600100</td>\n",
       "      <td>0.071384</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lem_char_count  lem_word_count  lem_unique_word_count  sentence_count  \\\n",
       "17405        0.063722        0.070363               0.107901        0.029289   \n",
       "11323        0.037368        0.041007               0.068819        0.037657   \n",
       "18975        0.053889        0.058248               0.100255        0.020921   \n",
       "8934         0.050461        0.060112               0.092608        0.025105   \n",
       "594          0.054450        0.064772               0.105353        0.029289   \n",
       "\n",
       "       avg_words_per_sentence  sentiment  stopword_count  word_stopword_ratio  \n",
       "17405                0.132867   0.986747        0.048842                0.255  \n",
       "11323                0.062937   0.878720        0.030056                0.270  \n",
       "18975                0.146853   0.023256        0.047589                0.300  \n",
       "8934                 0.132867   0.014904        0.053225                0.325  \n",
       "594                  0.125874   0.600100        0.071384                0.405  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_part1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c104c3",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "Begin with the random forest classifier algorithm. Write a function that utilizes grid search and cross-validation to optimize it and return the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37db0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_models(X_train, y_train, param_dict, cv = 5):\n",
    "    \"\"\"\n",
    "    This function creates and returns an optimized random forest classification model. It also\n",
    "    prints out the best model's mean cross-validated accuracy score and parameters.\n",
    "    \n",
    "    This function takes in the X and y training sets to fit the models.\n",
    "    \n",
    "    This function takes in a dictionary that contains the parameters to be iterated through.\n",
    "    \n",
    "    This function also takes in a value for the number of cross validation folds to do.\n",
    "    The cv value defaults to 5.\n",
    "    \"\"\"\n",
    "    #Create the classifier model\n",
    "    clf = RandomForestClassifier(random_state = 123)\n",
    "    \n",
    "    #Create the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, param_dict, cv = cv)\n",
    "    \n",
    "    #Fit the GridSearchCV object\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    #Print the best model's score and parameters\n",
    "    print('Mean Cross-Validated Accuracy: ', round(grid.best_score_, 4))\n",
    "    print('Max Depth: ', grid.best_params_['max_depth'])\n",
    "    print('Min Samples Per Leaf: ', grid.best_params_['min_samples_leaf'])\n",
    "    \n",
    "    #Return the best model\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a570a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dictionary of parameters and their values to iterate through\n",
    "rf_dict = {\n",
    "    'max_depth': range(5, 16),\n",
    "    'min_samples_leaf': range(1, 11)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fabaa7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy:  0.4351\n",
      "Max Depth:  14\n",
      "Min Samples Per Leaf:  4\n"
     ]
    }
   ],
   "source": [
    "best_model = get_random_forest_models(X_train_part1, y_train, rf_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
