{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffcb45a",
   "metadata": {},
   "source": [
    "# Model the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18468ec7",
   "metadata": {},
   "source": [
    "For my MVP, I would like to use several algorithms with cross-validation and grid search. The algorithms I plan on using are:\n",
    "\n",
    "* Random Forest Classifier\n",
    "* K-Nearest Neighbors\n",
    "* Gaussian Naive Bayes\n",
    "* Multinomial Naive Bayes\n",
    "* XGBoost (If I can get it to work. I will attempt this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f0bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7083e",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1e83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurbs = pd.read_csv('blurbs_for_exploration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a3f7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>sub-genre</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>lem_char_count</th>\n",
       "      <th>lem_word_count</th>\n",
       "      <th>lem_unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>word_stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>Designed to appeal to the book lover, the Macm...</td>\n",
       "      <td>designed appeal book lover macmillan collector...</td>\n",
       "      <td>design appeal book lover macmillan collector '...</td>\n",
       "      <td>designed appeal book lover macmillan collector...</td>\n",
       "      <td>1102</td>\n",
       "      <td>147</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>96</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>Part of the Penguin Orange Collection, a limit...</td>\n",
       "      <td>part penguin orange collection limitedrun seri...</td>\n",
       "      <td>part penguin orang collect limitedrun seri twe...</td>\n",
       "      <td>part penguin orange collection limitedrun seri...</td>\n",
       "      <td>954</td>\n",
       "      <td>118</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>55</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>Part of a new six-volume series of the best in...</td>\n",
       "      <td>part new sixvolume series best classic horror ...</td>\n",
       "      <td>part new sixvolum seri best classic horror sel...</td>\n",
       "      <td>part new sixvolume series best classic horror ...</td>\n",
       "      <td>1260</td>\n",
       "      <td>173</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.2144</td>\n",
       "      <td>85</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>A USA TODAY BESTSELLER!An Indie Next Pick!An O...</td>\n",
       "      <td>usa today bestselleran indie next pickan octob...</td>\n",
       "      <td>usa today bestselleran indi next pickan octob ...</td>\n",
       "      <td>usa today bestselleran indie next pickan octob...</td>\n",
       "      <td>800</td>\n",
       "      <td>104</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.9530</td>\n",
       "      <td>63</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Horror</td>\n",
       "      <td>ghost-stories</td>\n",
       "      <td>From the New York Times best-selling author of...</td>\n",
       "      <td>new york times bestselling author southern boo...</td>\n",
       "      <td>new york time bestsel author southern book clu...</td>\n",
       "      <td>new york time bestselling author southern book...</td>\n",
       "      <td>603</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.9726</td>\n",
       "      <td>28</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre      sub-genre                                           original  \\\n",
       "0  Horror  ghost-stories  Designed to appeal to the book lover, the Macm...   \n",
       "1  Horror  ghost-stories  Part of the Penguin Orange Collection, a limit...   \n",
       "2  Horror  ghost-stories  Part of a new six-volume series of the best in...   \n",
       "3  Horror  ghost-stories  A USA TODAY BESTSELLER!An Indie Next Pick!An O...   \n",
       "4  Horror  ghost-stories  From the New York Times best-selling author of...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  designed appeal book lover macmillan collector...   \n",
       "1  part penguin orange collection limitedrun seri...   \n",
       "2  part new sixvolume series best classic horror ...   \n",
       "3  usa today bestselleran indie next pickan octob...   \n",
       "4  new york times bestselling author southern boo...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  design appeal book lover macmillan collector '...   \n",
       "1  part penguin orang collect limitedrun seri twe...   \n",
       "2  part new sixvolum seri best classic horror sel...   \n",
       "3  usa today bestselleran indi next pickan octob ...   \n",
       "4  new york time bestsel author southern book clu...   \n",
       "\n",
       "                                          lemmatized  lem_char_count  \\\n",
       "0  designed appeal book lover macmillan collector...            1102   \n",
       "1  part penguin orange collection limitedrun seri...             954   \n",
       "2  part new sixvolume series best classic horror ...            1260   \n",
       "3  usa today bestselleran indie next pickan octob...             800   \n",
       "4  new york time bestselling author southern book...             603   \n",
       "\n",
       "   lem_word_count  lem_unique_word_count  sentence_count  \\\n",
       "0             147                    120               8   \n",
       "1             118                     87               2   \n",
       "2             173                    138               7   \n",
       "3             104                     92               2   \n",
       "4              77                     74               5   \n",
       "\n",
       "   avg_words_per_sentence  sentiment  stopword_count  word_stopword_ratio  \n",
       "0                      18     0.9582              96                 0.65  \n",
       "1                      59     0.9100              55                 0.47  \n",
       "2                      25    -0.2144              85                 0.49  \n",
       "3                      52    -0.9530              63                 0.61  \n",
       "4                      15    -0.9726              28                 0.36  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd0163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21414 entries, 0 to 21413\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   genre                   21414 non-null  object \n",
      " 1   sub-genre               21414 non-null  object \n",
      " 2   original                21414 non-null  object \n",
      " 3   clean                   21414 non-null  object \n",
      " 4   stemmed                 21414 non-null  object \n",
      " 5   lemmatized              21414 non-null  object \n",
      " 6   lem_char_count          21414 non-null  int64  \n",
      " 7   lem_word_count          21414 non-null  int64  \n",
      " 8   lem_unique_word_count   21414 non-null  int64  \n",
      " 9   sentence_count          21414 non-null  int64  \n",
      " 10  avg_words_per_sentence  21414 non-null  int64  \n",
      " 11  sentiment               21414 non-null  float64\n",
      " 12  stopword_count          21414 non-null  int64  \n",
      " 13  word_stopword_ratio     21414 non-null  float64\n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "blurbs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae24c6d",
   "metadata": {},
   "source": [
    "# Split the Data\n",
    "\n",
    "Since I will be using cross-validation, I won't need a validation set. Only train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e9655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16060, 14), (5354, 14))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(blurbs, stratify = blurbs.genre, test_size = .25, random_state = 123)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75ec1e",
   "metadata": {},
   "source": [
    "# Create X and y Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f975c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop(columns = ['genre']), train.genre\n",
    "X_test, y_test = test.drop(columns = ['genre']), test.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65613cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16060, 13), (16060,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check train shapes\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8244671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5354, 13), (5354,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check test shapes\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502a2c9",
   "metadata": {},
   "source": [
    "# Scale the X Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2293f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Fit and transform the data on train \n",
    "X_train[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']] = scaler.fit_transform(X_train[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']])\n",
    "\n",
    "#Transform the data on test\n",
    "X_test[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']] = scaler.transform(X_test[['lem_char_count', 'lem_word_count', 'lem_unique_word_count', 'sentence_count', 'avg_words_per_sentence', 'sentiment', 'stopword_count', 'word_stopword_ratio']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be75f0",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Make predictions using only the engineered features, not the term frequencies or TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892329f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the engineered features\n",
    "X_train_part1 = X_train.drop(columns = ['sub-genre', 'original', 'clean', 'stemmed', 'lemmatized'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "818737a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lem_char_count</th>\n",
       "      <th>lem_word_count</th>\n",
       "      <th>lem_unique_word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>word_stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17405</th>\n",
       "      <td>0.063722</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>0.107901</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.986747</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.041007</td>\n",
       "      <td>0.068819</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.878720</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>0.053889</td>\n",
       "      <td>0.058248</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>0.050461</td>\n",
       "      <td>0.060112</td>\n",
       "      <td>0.092608</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.054450</td>\n",
       "      <td>0.064772</td>\n",
       "      <td>0.105353</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.600100</td>\n",
       "      <td>0.071384</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lem_char_count  lem_word_count  lem_unique_word_count  sentence_count  \\\n",
       "17405        0.063722        0.070363               0.107901        0.029289   \n",
       "11323        0.037368        0.041007               0.068819        0.037657   \n",
       "18975        0.053889        0.058248               0.100255        0.020921   \n",
       "8934         0.050461        0.060112               0.092608        0.025105   \n",
       "594          0.054450        0.064772               0.105353        0.029289   \n",
       "\n",
       "       avg_words_per_sentence  sentiment  stopword_count  word_stopword_ratio  \n",
       "17405                0.132867   0.986747        0.048842                0.255  \n",
       "11323                0.062937   0.878720        0.030056                0.270  \n",
       "18975                0.146853   0.023256        0.047589                0.300  \n",
       "8934                 0.132867   0.014904        0.053225                0.325  \n",
       "594                  0.125874   0.600100        0.071384                0.405  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_part1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72afc5d2",
   "metadata": {},
   "source": [
    "### Create Baseline\n",
    "\n",
    "I will use the dummy classifier with a stratify strategy to create my baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193479f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27017434620174346"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate the model\n",
    "baseline_model = DummyClassifier(strategy = 'stratified', random_state = 123)\n",
    "\n",
    "#Fit the model\n",
    "baseline_model.fit(X_train_part1, y_train)\n",
    "\n",
    "#Score the model\n",
    "baseline_model.score(X_train_part1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93d312",
   "metadata": {},
   "source": [
    "__Baseline Accuracy: 27%__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1d7d1",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "Begin with the random forest classifier algorithm. Write a function that utilizes grid search and cross-validation to optimize it and return the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bad9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_models(X_train, y_train, param_dict, cv = 5):\n",
    "    \"\"\"\n",
    "    This function creates and returns an optimized random forest classification model. It also\n",
    "    prints out the best model's mean cross-validated accuracy score and parameters.\n",
    "    \n",
    "    This function takes in the X and y training sets to fit the models.\n",
    "    \n",
    "    This function takes in a dictionary that contains the parameters to be iterated through.\n",
    "    \n",
    "    This function also takes in a value for the number of cross validation folds to do.\n",
    "    The cv value defaults to 5.\n",
    "    \"\"\"\n",
    "    #Create the classifier model\n",
    "    clf = RandomForestClassifier(random_state = 123)\n",
    "    \n",
    "    #Create the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, param_dict, cv = cv)\n",
    "    \n",
    "    #Fit the GridSearchCV object\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    #Print the best model's score and parameters\n",
    "    print('Mean Cross-Validated Accuracy: ', round(grid.best_score_, 4))\n",
    "    print('Max Depth: ', grid.best_params_['max_depth'])\n",
    "    print('Min Samples Per Leaf: ', grid.best_params_['min_samples_leaf'])\n",
    "    \n",
    "    #Return the best model\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5871f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dictionary of parameters and their values to iterate through\n",
    "rf_dict = {\n",
    "    'max_depth': range(14, 26),\n",
    "    'min_samples_leaf': range(1, 16)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e60068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_rf_model = get_random_forest_models(X_train_part1, y_train, rf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea0a86",
   "metadata": {},
   "source": [
    "Best Attempt:\n",
    "\n",
    "- Mean Cross-Validated Accuracy: 0.4351\n",
    "- Max Depth: 14\n",
    "- Min Samples Per Leaf: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fee507",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "Now write a function to create an optimized K-Nearest Neighbors model. It will behave like the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee3350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KNN_models(X_train_scaled, y_train, param_dict, cv = 5):\n",
    "    \"\"\"\n",
    "    This function takes in scaled data and builds an optimized KNN classification model. \n",
    "    It will use the parameters specified in the param_dict to optimizie across.\n",
    "    \n",
    "    This function utilizes GridSearchCV.\n",
    "    \n",
    "    This function returns the best model and prints out its parameters and mean\n",
    "    cross-validated accuracy.\n",
    "    \"\"\"\n",
    "    #Create the KNN model\n",
    "    clf = KNeighborsClassifier()\n",
    "    \n",
    "    #Create the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, param_dict, cv = cv)\n",
    "    \n",
    "    #Fit the GridSearchCV object\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Print the best model's score and parameters\n",
    "    print('Mean Cross-Validated Accuracy: ', round(grid.best_score_, 4))\n",
    "    print('Num Neighbors: ', grid.best_params_['n_neighbors'])\n",
    "    print('Weights: ', grid.best_params_['weights'])\n",
    "    \n",
    "    #Return the best model\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f778ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dict of parameters and their values to optimize across\n",
    "knn_dict = {\n",
    "    'n_neighbors': range(10, 500, 10),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fb03c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy:  0.4215\n",
      "Num Neighbors:  130\n",
      "Weights:  distance\n"
     ]
    }
   ],
   "source": [
    "#best_knn_model = get_KNN_models(X_train_part1, y_train, knn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d3edf",
   "metadata": {},
   "source": [
    "Best Attempt:\n",
    "\n",
    "- Mean Cross-Validated Accuracy: 0.4215\n",
    "- Num Neighbors: 130\n",
    "- Weights: distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9cd40",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "Write a function that creates a Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d664ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gauss_models(X_train_scaled, y_train, param_dict, cv = 5):\n",
    "    \"\"\"\n",
    "    This function will create an optimized Gaussian Naive Bayes classification model. It will\n",
    "    use the X_train_scaled and y_train data for fitting. The param_dict contains the parameters\n",
    "    and their values that the GridSearchCV function will optimize across. The cv parameter\n",
    "    indicates how many folds will be fitted and evaluated, and defaults to 5.\n",
    "    \n",
    "    This function prints out the mean cross-validated accuracy, best paramters, and returns\n",
    "    the best model.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create the Gaussian Naive Bayes model\n",
    "    clf = GaussianNB()\n",
    "    \n",
    "    #Create the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, param_dict, cv = cv)\n",
    "    \n",
    "    #Fit the GridSearchCV object\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Print the best model's score and parameters\n",
    "    print('Mean Cross-Validated Accuracy: ', round(grid.best_score_, 4))\n",
    "    print('Smoothing: ', grid.best_params_['var_smoothing'])\n",
    "    \n",
    "    #Return the best model\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00b19980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the param_dict\n",
    "gauss_dict = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e24fe3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy:  0.3993\n",
      "Smoothing:  0.03511191734215131\n"
     ]
    }
   ],
   "source": [
    "#best_gauss_model = get_gauss_models(X_train_part1, y_train, gauss_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0521e",
   "metadata": {},
   "source": [
    "Best Attempt:\n",
    "\n",
    "- Mean Cross-Validated Accuracy: 0.3993\n",
    "- Smoothing: 0.035"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cdb702",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "Write a function that creates a multinomial naive bayes model. I know this function is better suited to event driven counts, but I want to see if it will work using the engineered features in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e5bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multinomial_models(X_train_scaled, y_train, param_dict, cv = 5):\n",
    "    \"\"\"\n",
    "    This function will create an optimized Multinomial Naive Bayes classification model. It will\n",
    "    use the X_train_scaled and y_train data for fitting. The param_dict contains the parameters\n",
    "    and their values that the GridSearchCV function will optimize across. The cv parameter\n",
    "    indicates how many folds will be fitted and evaluated, and defaults to 5.\n",
    "    \n",
    "    This function prints out the mean cross-validated accuracy, best paramters, and returns\n",
    "    the best model.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create the Multinomial Niave Bayes model\n",
    "    clf = MultinomialNB()\n",
    "    \n",
    "    #Create the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, param_dict, cv = cv)\n",
    "    \n",
    "    #Fit the GridSearchCV object\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Print the best model's score and parameters\n",
    "    print('Mean Cross-Validated Accuracy: ', round(grid.best_score_, 4))\n",
    "    print('Alpha: ', grid.best_params_['alpha'])\n",
    "    print('Fit Prior: ', grid.best_params_['fit_prior'])\n",
    "    \n",
    "    #Return the best model\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca9f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the param_dict\n",
    "multinomial_dict = {\n",
    "    'alpha': range(1, 101),\n",
    "    'fit_prior': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb114385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy:  0.3217\n",
      "Alpha:  1\n",
      "Fit Prior:  True\n"
     ]
    }
   ],
   "source": [
    "#Get the multinomial models\n",
    "#best_multinomial_model = get_multinomial_models(X_train_part1, y_train, multinomial_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3e47c",
   "metadata": {},
   "source": [
    "Best Attempt:\n",
    "\n",
    "- Mean Cross-Validated Accuracy: 0.3217\n",
    "- Alpha: 1\n",
    "- Fit Prior: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7101c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
